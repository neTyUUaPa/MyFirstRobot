This code for the robot was created for a training module in which the robot had to move around the field at the end. His task was to drive autonomously through the hallway and each room and collect items (cans, pizza boxes and toys).
![alt text](https://github.com/neTyUUaPa/MyFirstRobot/blob/main/Map/Map.png)
As part of this task, several test variants of movement algorithms in WeBots were developed, the first was the construction of a map using lidar according to A* (then this algorithm was used almost everywhere), then it was the movement of an earlier map, and the last algorithm was the use of a very small map in which the relative location of walls and rooms was located in order to reduce the weight of the card for Arduino and the movement and orientation of the ultrasonic sensors on the sides. Further, attempts were made to implement this already on the robot and the first two options disappeared, the last option was practically implemented, but was not fully configured. Therefore, an option was implemented, a simpler option for moving along the graph.
It also implemented color recognition of an object on the camera through OpenCV and a search for a relative angle, for which a polynomial model was made.
